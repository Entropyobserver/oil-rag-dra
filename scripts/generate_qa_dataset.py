#!/usr/bin/env python3


import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))

import json
import random
import re
from typing import List, Dict, Tuple, Any
from datetime import datetime
import openai
from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM
import nltk
from nltk.tokenize import sent_tokenize, word_tokenize
from nltk.corpus import stopwords
import spacy
from config.config import config

# ä¸‹è½½å¿…è¦çš„NLTKæ•°æ®
try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    nltk.download('punkt')

try:
    nltk.data.find('corpora/stopwords')
except LookupError:
    nltk.download('stopwords')


class QADatasetGenerator:
    """QAæ•°æ®é›†ç”Ÿæˆå™¨"""
    
    def __init__(self, use_llm: bool = True):
        """
        åˆå§‹åŒ–ç”Ÿæˆå™¨
        Args:
            use_llm: æ˜¯å¦ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆé—®é¢˜
        """
        self.use_llm = use_llm
        self.categories = [
            "production", "operations", "strategy", "technology", 
            "financial", "environment", "safety", "projects", "exploration"
        ]
        
        # é—®é¢˜æ¨¡æ¿
        self.question_templates = {
            "production": [
                "How much {resource} was produced in {year}?",
                "What were the production levels for {year}?",
                "What factors affected production in {year}?",
                "How did production change compared to previous year?"
            ],
            "operations": [
                "What operational challenges were faced in {year}?",
                "How were offshore operations managed in {year}?",
                "What safety measures were implemented in operations?",
                "How did operations change in {year}?"
            ],
            "strategy": [
                "What was the business strategy for {year}?",
                "How did the business strategy evolve in {year}?",
                "What strategic initiatives were announced?",
                "What were the key strategic priorities?"
            ],
            "technology": [
                "What new technologies were implemented in {year}?",
                "How was technology used to improve operations in {year}?",
                "What digital transformation initiatives were undertaken?",
                "What innovation projects were launched?"
            ],
            "financial": [
                "What were the financial results for {year}?",
                "How did revenue perform in {year}?",
                "What was the profitability in {year}?",
                "What were the key financial highlights?"
            ],
            "environment": [
                "What environmental initiatives were taken in {year}?",
                "How did the company address climate change?",
                "What sustainability goals were set?",
                "What environmental performance was achieved?"
            ],
            "safety": [
                "What safety measures were implemented?",
                "How was workplace safety ensured?",
                "What safety performance was achieved in {year}?",
                "What safety incidents occurred?"
            ],
            "projects": [
                "What major projects were completed in {year}?",
                "What capital projects were approved in {year}?",
                "What new developments were announced?",
                "What project milestones were achieved?"
            ],
            "exploration": [
                "What exploration activities took place in {year}?",
                "What new discoveries were made?",
                "What exploration results were reported?",
                "Where did exploration activities focus?"
            ]
        }
        
        # åŠ è½½spaCyæ¨¡å‹ç”¨äºå®ä½“è¯†åˆ«
        try:
            self.nlp = spacy.load("en_core_web_sm")
        except OSError:
            print("Warning: spaCy English model not found. Install with: python -m spacy download en_core_web_sm")
            self.nlp = None
        
        # å¦‚æœä½¿ç”¨LLMï¼Œåˆå§‹åŒ–æ¨¡å‹
        if self.use_llm:
            self._init_llm()
    
    def _init_llm(self):
        """åˆå§‹åŒ–å¤§è¯­è¨€æ¨¡å‹"""
        try:
            # å°è¯•ä½¿ç”¨T5æ¨¡å‹è¿›è¡Œé—®é¢˜ç”Ÿæˆ
            self.tokenizer = AutoTokenizer.from_pretrained("t5-base")
            self.model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")
            self.qa_pipeline = pipeline(
                "text2text-generation",
                model=self.model,
                tokenizer=self.tokenizer,
                max_length=512
            )
            print("âœ… T5æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸ LLMåˆå§‹åŒ–å¤±è´¥: {e}")
            self.use_llm = False
    
    def load_aligned_documents(self, data_dir: str = "data/processed/aligned") -> List[Dict]:
        """åŠ è½½å¯¹é½çš„æ–‡æ¡£æ•°æ®"""
        documents = []
        data_path = Path(data_dir)
        
        for file_path in data_path.glob("aligned_*.jsonl"):
            if "stats" not in file_path.name:
                with open(file_path, 'r', encoding='utf-8') as f:
                    for line in f:
                        doc = json.loads(line)
                        documents.append(doc)
        
        print(f"âœ… åŠ è½½äº† {len(documents)} ä¸ªæ–‡æ¡£")
        return documents
    
    def extract_key_info(self, text: str) -> Dict[str, Any]:
        """ä»æ–‡æœ¬ä¸­æå–å…³é”®ä¿¡æ¯"""
        info = {
            "entities": [],
            "numbers": [],
            "dates": [],
            "keywords": []
        }
        
        if self.nlp:
            doc = self.nlp(text)
            # æå–å‘½åå®ä½“
            for ent in doc.ents:
                if ent.label_ in ["ORG", "PERSON", "GPE", "MONEY", "PERCENT", "DATE"]:
                    info["entities"].append({
                        "text": ent.text,
                        "label": ent.label_
                    })
        
        # æå–æ•°å­—å’Œæ—¥æœŸ
        numbers = re.findall(r'\\d+(?:[.,]\\d+)*(?:\\s*(?:million|billion|thousand))?', text)
        info["numbers"] = numbers
        
        dates = re.findall(r'\\b\\d{4}\\b|\\b(?:January|February|March|April|May|June|July|August|September|October|November|December)\\b', text)
        info["dates"] = dates
        
        return info
    
    def classify_document(self, doc: Dict) -> str:
        """å¯¹æ–‡æ¡£è¿›è¡Œåˆ†ç±»"""
        text = doc["en"]["text"].lower()
        
        # åŸºäºå…³é”®è¯çš„ç®€å•åˆ†ç±»
        category_keywords = {
            "production": ["production", "output", "barrel", "gas", "oil", "mboe"],
            "operations": ["operation", "facility", "platform", "offshore", "drilling"],
            "strategy": ["strategy", "plan", "goal", "vision", "mission", "objective"],
            "technology": ["technology", "digital", "innovation", "system", "automation"],
            "financial": ["revenue", "profit", "cost", "investment", "financial", "million", "billion"],
            "environment": ["environment", "emission", "carbon", "sustainability", "climate"],
            "safety": ["safety", "accident", "incident", "injury", "security"],
            "projects": ["project", "development", "construction", "investment", "capital"],
            "exploration": ["exploration", "discovery", "reserve", "drilling", "well"]
        }
        
        max_score = 0
        best_category = "operations"  # é»˜è®¤ç±»åˆ«
        
        for category, keywords in category_keywords.items():
            score = sum(1 for keyword in keywords if keyword in text)
            if score > max_score:
                max_score = score
                best_category = category
        
        return best_category
    
    def generate_template_questions(self, doc: Dict, category: str) -> List[Dict]:
        """åŸºäºæ¨¡æ¿ç”Ÿæˆé—®é¢˜"""
        questions = []
        year = doc["en"]["year"]
        text = doc["en"]["text"]
        
        # ä»æ–‡æœ¬ä¸­æå–èµ„æºç±»å‹
        resources = ["oil", "gas", "petroleum", "energy"]
        found_resources = [r for r in resources if r in text.lower()]
        resource = found_resources[0] if found_resources else "oil"
        
        templates = self.question_templates.get(category, self.question_templates["operations"])
        
        for template in templates[:2]:  # æ¯ä¸ªæ–‡æ¡£ç”Ÿæˆ2ä¸ªé—®é¢˜
            try:
                question = template.format(year=year, resource=resource)
                
                # ç”Ÿæˆç®€å•ç­”æ¡ˆï¼ˆå–æ–‡æœ¬çš„å‰200ä¸ªå­—ç¬¦ï¼‰
                answer = text[:400] + "..." if len(text) > 400 else text
                
                qa_pair = {
                    "id": f"{category}_{random.randint(1000, 9999)}",
                    "question": question,
                    "answer": answer,
                    "category": category,
                    "year": year,
                    "doc_id": doc["en"]["id"],
                    "context": text[:500],
                    "method": "template"
                }
                questions.append(qa_pair)
            except KeyError:
                continue
        
        return questions
    
    def generate_llm_questions(self, doc: Dict, category: str) -> List[Dict]:
        """ä½¿ç”¨LLMç”Ÿæˆæ›´è‡ªç„¶çš„é—®é¢˜"""
        if not self.use_llm:
            return []
        
        questions = []
        text = doc["en"]["text"]
        year = doc["en"]["year"]
        
        # åˆ›å»ºæç¤º
        prompt = f"Generate a question about {category} based on this text: {text[:300]}"
        
        try:
            # ä½¿ç”¨T5ç”Ÿæˆé—®é¢˜
            inputs = f"generate question: {text[:400]}"
            result = self.qa_pipeline(inputs, max_length=100, num_return_sequences=1)
            
            question = result[0]["generated_text"]
            
            # ç”Ÿæˆç­”æ¡ˆï¼ˆç®€å•ç­–ç•¥ï¼šä½¿ç”¨åŸæ–‡æœ¬ï¼‰
            answer = text[:400] + "..." if len(text) > 400 else text
            
            qa_pair = {
                "id": f"{category}_{random.randint(1000, 9999)}",
                "question": question,
                "answer": answer,
                "category": category,
                "year": year,
                "doc_id": doc["en"]["id"],
                "context": text[:500],
                "method": "llm"
            }
            questions.append(qa_pair)
            
        except Exception as e:
            print(f"LLMç”Ÿæˆå¤±è´¥: {e}")
        
        return questions
    
    def generate_factual_questions(self, doc: Dict) -> List[Dict]:
        """ç”ŸæˆåŸºäºäº‹å®çš„é—®é¢˜"""
        questions = []
        text = doc["en"]["text"]
        year = doc["en"]["year"]
        
        # æå–æ•°å­—ä¿¡æ¯ç”Ÿæˆé—®é¢˜
        numbers = re.findall(r'(\\d+(?:[.,]\\d+)*(?:\\s*(?:million|billion|thousand|%))?)', text)
        
        for number in numbers[:2]:  # ä¸ºå‰2ä¸ªæ•°å­—ç”Ÿæˆé—®é¢˜
            question = f"What was the figure of {number} mentioned in the {year} report?"
            answer = text[:400] + "..." if len(text) > 400 else text
            
            qa_pair = {
                "id": f"factual_{random.randint(1000, 9999)}",
                "question": question,
                "answer": answer,
                "category": "factual",
                "year": year,
                "doc_id": doc["en"]["id"],
                "context": text[:500],
                "method": "factual"
            }
            questions.append(qa_pair)
        
        return questions
    
    def generate_qa_dataset(self, 
                          input_dir: str = "data/processed/aligned",
                          output_file: str = "data/generated_qa_dataset.jsonl",
                          max_documents: int = 1000,
                          questions_per_doc: int = 3) -> str:
        """
        ç”Ÿæˆå®Œæ•´çš„QAæ•°æ®é›†
        
        Args:
            input_dir: è¾“å…¥æ–‡æ¡£ç›®å½•
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            max_documents: æœ€å¤§å¤„ç†æ–‡æ¡£æ•°
            questions_per_doc: æ¯ä¸ªæ–‡æ¡£ç”Ÿæˆçš„é—®é¢˜æ•°
        
        Returns:
            ç”Ÿæˆçš„æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯
        """
        print("ğŸš€ å¼€å§‹ç”ŸæˆQAæ•°æ®é›†...")
        
        # åŠ è½½æ–‡æ¡£
        documents = self.load_aligned_documents(input_dir)
        
        # éšæœºé‡‡æ ·æ–‡æ¡£
        if len(documents) > max_documents:
            documents = random.sample(documents, max_documents)
        
        all_questions = []
        stats = {
            "total_documents": len(documents),
            "total_questions": 0,
            "categories": {cat: 0 for cat in self.categories},
            "methods": {"template": 0, "llm": 0, "factual": 0}
        }
        
        for i, doc in enumerate(documents):
            if i % 100 == 0:
                print(f"å¤„ç†è¿›åº¦: {i}/{len(documents)}")
            
            try:
                # åˆ†ç±»æ–‡æ¡£
                category = self.classify_document(doc)
                
                # ç”Ÿæˆä¸åŒç±»å‹çš„é—®é¢˜
                doc_questions = []
                
                # 1. æ¨¡æ¿é—®é¢˜ï¼ˆæ¯ä¸ªæ–‡æ¡£è‡³å°‘1ä¸ªï¼‰
                template_qs = self.generate_template_questions(doc, category)
                doc_questions.extend(template_qs)
                
                # 2. LLMé—®é¢˜ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                if self.use_llm and len(doc_questions) < questions_per_doc:
                    llm_qs = self.generate_llm_questions(doc, category)
                    doc_questions.extend(llm_qs)
                
                # 3. äº‹å®æ€§é—®é¢˜
                if len(doc_questions) < questions_per_doc:
                    factual_qs = self.generate_factual_questions(doc)
                    doc_questions.extend(factual_qs)
                
                # é™åˆ¶æ¯ä¸ªæ–‡æ¡£çš„é—®é¢˜æ•°é‡
                doc_questions = doc_questions[:questions_per_doc]
                
                # æ›´æ–°ç»Ÿè®¡
                for q in doc_questions:
                    stats["categories"][q["category"]] += 1
                    stats["methods"][q["method"]] += 1
                
                all_questions.extend(doc_questions)
                
            except Exception as e:
                print(f"å¤„ç†æ–‡æ¡£å¤±è´¥: {e}")
                continue
        
        # ä¿å­˜æ•°æ®é›†
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            for question in all_questions:
                f.write(json.dumps(question, ensure_ascii=False) + '\\n')
        
        stats["total_questions"] = len(all_questions)
        
        # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
        stats_file = output_path.with_suffix('.stats.json')
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(stats, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… QAæ•°æ®é›†ç”Ÿæˆå®Œæˆ!")
        print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   æ€»æ–‡æ¡£æ•°: {stats['total_documents']}")
        print(f"   æ€»é—®é¢˜æ•°: {stats['total_questions']}")
        print(f"   å¹³å‡æ¯æ–‡æ¡£: {stats['total_questions']/stats['total_documents']:.1f}ä¸ªé—®é¢˜")
        print(f"   è¾“å‡ºæ–‡ä»¶: {output_path}")
        
        return str(output_path)


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ç”ŸæˆQAæ•°æ®é›†')
    parser.add_argument('--input_dir', default='data/processed/aligned',
                       help='è¾“å…¥æ–‡æ¡£ç›®å½•')
    parser.add_argument('--output_file', default='data/test/generated_qa_dataset.jsonl',
                       help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--max_docs', type=int, default=1000,
                       help='æœ€å¤§å¤„ç†æ–‡æ¡£æ•°')
    parser.add_argument('--questions_per_doc', type=int, default=3,
                       help='æ¯ä¸ªæ–‡æ¡£ç”Ÿæˆçš„é—®é¢˜æ•°')
    parser.add_argument('--use_llm', action='store_true',
                       help='ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆé—®é¢˜')
    
    args = parser.parse_args()
    
    # åˆ›å»ºç”Ÿæˆå™¨
    generator = QADatasetGenerator(use_llm=args.use_llm)
    
    # ç”Ÿæˆæ•°æ®é›†
    output_file = generator.generate_qa_dataset(
        input_dir=args.input_dir,
        output_file=args.output_file,
        max_documents=args.max_docs,
        questions_per_doc=args.questions_per_doc
    )
    
    print(f"ğŸ‰ æ•°æ®é›†å·²ç”Ÿæˆ: {output_file}")


if __name__ == "__main__":
    main()